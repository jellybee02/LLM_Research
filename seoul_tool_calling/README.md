# LLM_Research

LLM 관련 프로젝트를 진행하면서 이에 대한 기록을 남기고자 이와 같은 내용의 스크립트를 남긴다. 

현재 스크립트의 전체적인 환경 구성은 따로 저장해놓도록 하겠다.

목적 : LLM 관련 기능 구현 Sample


--------------------------------------------------------------
2025-06-11
데이터 : 서울시 대여 공구 찾기 정보
https://data.seoul.go.kr/dataList/OA-21096/S/1/datasetView.do

선정 목적 : 필요한 공구를 갖고있는 위치에 대해서 공구 및 현재 위치를 말하면 가장 가까운 곳을 찾아주는 LLM 을 개발해보려고 함 

산출 결과 : 해당 공구가 있는 위치 정보를 가까운 순으로 추천해주고 관련 정보 를 같이 제공, 작업 내용에 대한 내용을 입력하게 되면 해당 대여소에서 추가적으로 대여할 수 있는 품목을 제시하려고 함

--------------------------------------------------------------
2025-06-12
LLM OpenAI GPT API 키 이용해서 출력 나오고 프롬프트 및 질문 관련 내용 입력할 수 있는 형태로 만들어놓기

------------------------------------------------------------------

2025-06-17
프롬프트의 관련 내용을 입력하여 물고있고, 관련 질문을 했을 때 대답하는지 확인


2025-06-25
User Input의 내용과 내부 데이터의 유사도를 비교하기 위해서 임베딩 벡터를 이용하여 유사도 비교를 실시할 예정.
임베딩 과정 중 컴퓨터 cuda 세팅이 안되어 있어 씨피유를 사용함.... 설치 필요

2025-06-26
1. 임베딩 값 완료
2. 임베딩 값 hdbscan으로 라벨 확인 후처리 필요
3. 임베딩 값 저장 및 라벨 처리 후 디비 저장 완료
향후 작업 : 라벨 전처리, 추천 관련 내용 상세화 필요함


2025-06-30

공구 클러스터 

---

2025-07-02

ver.GPT , ver.Gemma 버전 적용 완료 -> script/run_script.ipynb

---

**Work Flow**
사전 작업 : 데이터 전처리(결측치 및 시간 데이터처리 및 추가 컬럼)

1. User Input Content(도구, 장소, 작업내용)

2. 입력 정보 도구 encoding 및 장소 위도 경도 계산

3. encoding 값 기반 도구 유사도 0.9 이상 필터링

4. 필터링 값들 중 거리순 top3 필터링

5. 작업내용 기반 추가 대여 도구 및 작업 주의사항 전달

---

2025-07-13

기존의 py script로 구성했던 서비스를 streamlit을 이용해서 화면 구현까지 마쳤다.

현재 UI(Streamlit)에 서비스 구현에서 배포까지 진행해 보려고 한다. 

내용은 현재 만든 서비스를 이용해서 파이프라인을 구축해서 데이터의 정보를 입력부터 출력까지 전체 플로우 구성을 진행하려고 한다.

현재 docker를 활용해서 베포를 준비해보려고 하며, kafka와 postgreSQL을 이용한 데이터 저장 등을 이용하려고 한다.



