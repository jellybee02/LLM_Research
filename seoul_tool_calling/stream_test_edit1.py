import streamlit as st
from openai import OpenAI
from haversine import haversine, Unit
# from .script.run import get_lat_lon
import requests, pickle
import numpy as np, pandas as pd, warnings, os, json, openai
from tqdm.auto import tqdm
from openai import OpenAI
warnings.filterwarnings('ignore')
import requests
from typing import List, Tuple, Union
from langchain_ollama.embeddings import OllamaEmbeddings
import pickle
from sklearn.metrics.pairwise import cosine_similarity

# openai.api_key = "your-api-key"
key = open('../../../api_key.txt','r')

api_key = key.read()

 
openai.api_key = api_key
print(api_key)

with open('./data/encoded_tool_name2.pkl', "rb") as f:
    all_tool_encoded_array = pickle.load(f)
use_col = ['ê³µêµ¬ ì´ë¦„', 'ê³¼ê¸ˆê¸°ì¤€', 'ìˆ˜ëŸ‰','ëŒ€ì—¬ì¥ì†Œëª…', 'ìƒì„¸ì£¼ì†Œ','ì „í™”ë²ˆí˜¸', 'í‰ì¼ì˜¤í”ˆì‹œê°„', 'í‰ì¼í´ë¡œì¦ˆì‹œê°„', 'ìƒì„±ì¼ì‹œ', 'ìš”ê¸ˆ']
class OllamaSentenceTransformer():
    def __init__(
            self,
            *args,
            **kargs,
            ) -> None:
                # self.base_url = kargs.get()
                self.model = kargs.get("model","bge-m3")
                self.embedding_model = OllamaEmbeddings(
                            model = self.model,
                            # base_url = self.base_rul,
                        )
                        
    
    def encode(
            self,
            documents:Union[str, List[str], np.ndarray],
            *args,
            **kargs,
        )-> np.ndarray:
        if isinstance(documents, str):
            document_embeddings = self.embedding_model.embed_query(documents)
            return np.array(document_embeddings)
        
        if isinstance(documents, np.ndarray):
            documents = documents.tolist()
        
        document_embeddings = [self.embedding_model.embed_query(s) for s in documents]
        return np.array(document_embeddings)
        




sentence_transformer = OllamaSentenceTransformer()



def invoke(
           prompt,
           api_key=api_key,
           model="gpt-4o",
           temperature=0.7):
    client = OpenAI(api_key=api_key)

    # ë©”ì‹œì§€ êµ¬ì„±
    messages = [
        # {"role": "system", "content": prompt},
        {"role": "user", "content": prompt}
    ]
    # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
    stream = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        # stream=True  # â­ í•µì‹¬ ì˜µì…˜!
    )

    # generator ë°˜í™˜ (chunk ë‹¨ìœ„ í…ìŠ¤íŠ¸ ì¶œë ¥)
    return stream
    

def get_lat_lon(location_name):
    url = 'https://nominatim.openstreetmap.org/search'
    params = {
        'q': location_name,
        'format': 'json'
    }
    headers = {
        'User-Agent': 'Mozilla/5.0 (compatible; ChatGPT-Example/1.0; +http://yourdomain.com)'
    }

    response = requests.get(url, params=params, headers=headers)

    # ì‘ë‹µ í™•ì¸
    if response.status_code != 200:
        print(f"ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
        print("ì‘ë‹µ ë‚´ìš©:", response.text)
        return None

    try:
        data = response.json()
        if data:
            lat = data[0]['lat']
            lon = data[0]['lon']
            return float(lat), float(lon)
        else:
            print("ìœ„ì¹˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except ValueError as e:
        print("JSON íŒŒì‹± ì˜¤ë¥˜:", e)
        print("ì‘ë‹µ ë‚´ìš©:", response.text)
        return None


def compare_cosim(all_asset_encoded_val:np.array, asset_info:np.array) -> float:
    cos_sim = cosine_similarity(all_asset_encoded_val, [asset_info])
    return cos_sim

# ìƒ˜í”Œ ê³µêµ¬ ëŒ€ì—¬ì†Œ ë°ì´í„° (ìœ„ë„, ê²½ë„ í¬í•¨)


df = pd.read_csv("./data/prep3.csv", encoding='cp949')

# ì‚¬ìš©ì ì…ë ¥
st.title("ğŸ”§ ê³µêµ¬ ëŒ€ì—¬ ë„ìš°ë¯¸ ì±—ë´‡")

tool = st.text_input("ì›í•˜ëŠ” ê³µêµ¬ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì „ë™ë“œë¦´)")
location = st.text_input("ì›í•˜ëŠ” í˜„ì¬ ìœ„ì¹˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ê°•ë‚¨ì—­)")
content = st.text_input("ìˆ˜í–‰í•˜ë ¤ëŠ” ì‘ì—… ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ : ì „ë™ë“œë¦´ì„ ì‚¬ìš©í•´ì„œ ë‚˜ë¬´ë¥¼ ê³ ì •í•˜ê³  ì‹¶ì–´)")

# lat = st.number_input("í˜„ì¬ ìœ„ì¹˜ ìœ„ë„ ì…ë ¥", format="%.6f")
# lon = st.number_input("í˜„ì¬ ìœ„ì¹˜ ê²½ë„ ì…ë ¥", format="%.6f")
encoded_tool_name = sentence_transformer.encode(tool)
# location_name = input_content['location']
# spot_location = get_lat_lon(location_name)
df['tool_sim_result'] = compare_cosim(all_tool_encoded_array, encoded_tool_name)
df = df[df['tool_sim_result']>0.9]



if st.button("ëŒ€ì—¬ì†Œ ì°¾ê¸° ë° ì¶”ì²œ ë°›ê¸°"):
    if tool and location:
        # ê±°ë¦¬ ê³„ì‚°
        lat, lon = get_lat_lon(location) # ìœ„ë„, ê²½ë„
        df['distance_km'] = df[["ìœ„ë„","ê²½ë„"]].apply(lambda x : round(haversine((lat, lon), (x['ìœ„ë„'], x['ê²½ë„']), unit=Unit.KILOMETERS),3), axis=1)


        
        
        nearest = df.sort_values("distance_km").head(3)
        print(nearest)

        st.subheader("ğŸ“ ê°€ì¥ ê°€ê¹Œìš´ ê³µêµ¬ ëŒ€ì—¬ì†Œ Top 3")
        for _, row in nearest.iterrows():
            st.markdown(f"**{row['ëŒ€ì—¬ì¥ì†Œëª…']}**\n- ì£¼ì†Œ: {row['ìƒì„¸ì£¼ì†Œ']}\n- ê±°ë¦¬: {row['distance_km']:.2f} km")

        # GPTì—ê²Œ í•¨ê»˜ ì“°ê¸° ì¢‹ì€ ê³µêµ¬ ì¶”ì²œ ìš”ì²­
        with st.spinner("ê³µêµ¬ ì¡°í•© ì¶”ì²œ ì¤‘..."):
            if content is not None:
                prompt = f"""
                ë‚˜ëŠ” '{tool}'ì„ ë¹Œë¦¬ë ¤ê³  í•´.
                ê·¸ë¦¬ê³  {content}ëŠ” ë‚´ê°€ í•˜ë ¤ëŠ” ì‘ì—… ë‚´ìš©ì´ì•¼.
                í•´ë‹¹ ì‘ì—… ë‚´ìš©ì„ ì§„í–‰í•˜ê¸° ìœ„í•´ ê°™ì´ ëŒ€ì—¬í•˜ë©´ ì¢‹ì€ ì‘ì—… ë„êµ¬ë¥¼ ì…ë ¥í•´ì£¼ê³  ì™œ í•„ìš”í•œì§€ ì„¤ëª…í•´ì¤˜.
                ì‘ì—…ì„ ì§„í–‰í•  ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìœ„í—˜ ìƒí™©ì„ ê³ ë ¤í•´ì„œ ì£¼ì˜ì‚¬í•­ë„ í•¨ê»˜ ì‘ì„±í•´ì¤˜.
                """
            else:
                prompt = f"""
                ë‚˜ëŠ” '{tool}'ì„ ë¹Œë¦¬ë ¤ê³  í•´. í•¨ê»˜ ì“°ë©´ ìœ ìš©í•œ ë‹¤ë¥¸ ê³µêµ¬ 2~3ê°œë¥¼ ì¶”ì²œí•´ì¤˜.
                ì‘ì—…ì„ ì§„í–‰í•  ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìœ„í—˜ ìƒí™©ì„ ê³ ë ¤í•´ì„œ ì£¼ì˜ì‚¬í•­ë„ í•¨ê»˜ ì‘ì„±í•´ì¤˜.
               """
            
            response = invoke(prompt)
            answer = response.choices[0].message.content

        st.subheader("ğŸ›  í•¨ê»˜ ì‚¬ìš©í•˜ë©´ ì¢‹ì€ ê³µêµ¬ ì¶”ì²œ")
        st.markdown(answer)
    else:
        st.warning("ê³µêµ¬ ì´ë¦„ê³¼ ìœ„ì¹˜ ì •ë³´ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")






