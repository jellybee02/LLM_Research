{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92786eed",
   "metadata": {},
   "source": [
    "# README\n",
    "í•´ë‹¹ ì‘ì—…ì€ ê´€ë ¨ ì‘ì—…ë‚´ìš©ì„ ì§„í–‰í•˜ë˜ ì¤‘ ë­ê·¸ë˜í”„ì— ëŒ€í•œ ë‚´ìš©ì„ ì¸ì§€. \n",
    "\n",
    "ì§ˆë¬¸ì— ë”°ë¥¸ ì ì ˆí•œ GPT ì²˜ë¦¬ íë¦„(ì—­í• )ì„ ì„ íƒí•´ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì— ëŒ€í•´ì„œ ê¸°ìˆ  ê´€ì‹¬ì´ ìƒê¹€\n",
    "\n",
    "í•´ë‹¹ ë‚´ìš©ì— ëŒ€í•œ ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ì´ìš©í•´ë³´ë ¤ê³  í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a570550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "# from langchain_ollama.chat_models import ChatOpenAI\n",
    "# from langchain.schema import Sys\n",
    "from langgraph.graph import StateGraph, END\n",
    "# .graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b59114",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = open('../../../api_key.txt','r')\n",
    "api_key = key.read()\n",
    "# openai.api_key = api_key\n",
    "\n",
    "base_ = open('../../../base_url.txt','r')\n",
    "base_url = base_.read()\n",
    "# openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1855bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœ ì •ì˜ (ìš°ë¦¬ëŠ” ê°„ë‹¨íˆ dict ì”€)\n",
    "state_type = dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f591c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaEmbeddings(model='bge-m3', base_url='http://104.59.217.59:11434\\n', client_kwargs={}, async_client_kwargs={}, sync_client_kwargs={}, mirostat=None, mirostat_eta=None, mirostat_tau=None, num_ctx=None, num_gpu=None, keep_alive=None, num_thread=None, repeat_last_n=None, repeat_penalty=None, temperature=None, stop=None, tfs_z=None, top_k=None, top_p=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " = OllamaEmbeddings(model = 'bge-m3',\n",
    "                 base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3791b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model = 'gemma3:12b',\n",
    "                 base_url=base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model = 'gemma3:12b',\n",
    "                 base_url=base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e27e853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1271325/3614923015.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd91ef79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! ğŸ˜Š \\n\\nHow can I help you today?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('hi').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb315097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1: ì§ˆë¬¸ ë‚´ìš© êµ¬ë¶„ í•¨ìˆ˜\n",
    "def classify_question(stats):\n",
    "    # input_question = {\"question\": \"3 ê³±í•˜ê¸° 7ì€ ì–¼ë§ˆì•¼?\"}\n",
    "\n",
    "    question = stats[\"question\"]\n",
    "    messages = [\n",
    "                    {\"role\": \"system\", \n",
    "                        \"content\": f\"\"\"ë‹¹ì‹ ì€ ì§ˆë¬¸ì´ 'ìˆ˜í•™ ë¬¸ì œ'ì¸ì§€ ì•„ë‹Œì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤. \n",
    "                        ìˆ˜í•™ ë¬¸ì œë©´ 'math', ì•„ë‹ˆë©´ 'general'ë¡œë§Œ ëŒ€ë‹µí•˜ì„¸ìš”.\n",
    "                        \"\"\"\n",
    "                        },\n",
    "                    {\"role\": \"user\", \n",
    "                    \"content\": question}\n",
    "                ]\n",
    "    response = llm.invoke(messages).content.strip().lower()\n",
    "    stats['type']=response\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b7cb691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 2: ìˆ˜í•™ ì§ˆë¬¸ ì²˜ë¦¬\n",
    "def answer_math(state):\n",
    "    question = state[\"question\"]\n",
    "    messages = [\n",
    "                    {\"role\": \"system\", \n",
    "                        \"content\": f\"ë‹¹ì‹ ì€ ìˆ˜í•™ ë¬¸ì œë§Œ í‘¸ëŠ” ê³„ì‚°ê¸°ì…ë‹ˆë‹¤.\"\n",
    "                        },\n",
    "                    {\"role\": \"user\", \n",
    "                    \"content\": question}\n",
    "                ]\n",
    "    answer = llm.invoke(messages).content\n",
    "    state[\"answer\"] = answer\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37896774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 3: ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬\n",
    "def answer_general(state):\n",
    "    question = state[\"question\"]\n",
    "    messages = [\n",
    "                    {\"role\": \"system\", \n",
    "                        \"content\": f\"ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AIì…ë‹ˆë‹¤.\"\n",
    "                        },\n",
    "                    {\"role\": \"user\", \n",
    "                    \"content\": question}\n",
    "                ]\n",
    "    answer = llm.invoke(messages).content\n",
    "    state[\"answer\"] = answer\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26c098a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(state_schema=state_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96b60c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fae9625c8f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"classify\", classify_question)\n",
    "builder.add_node(\"math_mode\", answer_math)\n",
    "builder.add_node(\"general_mode\", answer_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77de16fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fae9625c8f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.set_entry_point(\"classify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "964fe79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶„ê¸° ì¡°ê±´ ì„¤ì •\n",
    "def route_based_on_type(state):\n",
    "    if state[\"type\"] == \"math\":\n",
    "        return \"math_mode\"\n",
    "    else:\n",
    "        return \"general_mode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d6c21f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fae9625c8f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_conditional_edges(\"classify\", route_based_on_type)\n",
    "builder.add_edge(\"math_mode\", END)\n",
    "builder.add_edge(\"general_mode\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b137592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b579592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ê·¼ì˜ ê³µì‹ ì„¤ëª… ë° ì˜ˆì‹œ\n",
      "\n",
      "ê·¼ì˜ ê³µì‹ì€ 2ì°¨ ë°©ì •ì‹ì˜ í•´ë¥¼ êµ¬í•˜ëŠ” ê³µì‹ì…ë‹ˆë‹¤. 2ì°¨ ë°©ì •ì‹ì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ í‘œí˜„ë©ë‹ˆë‹¤.\n",
      "\n",
      "**axÂ² + bx + c = 0**\n",
      "\n",
      "ì—¬ê¸°ì„œ a, b, cëŠ” ìƒìˆ˜ì´ë©°, aëŠ” 0ì´ ì•„ë‹ˆì–´ì•¼ í•©ë‹ˆë‹¤. ê·¼ì˜ ê³µì‹ì€ ì´ 2ì°¨ ë°©ì •ì‹ì˜ í•´(x ê°’)ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "**x = (-b Â± âˆš(bÂ² - 4ac)) / 2a**\n",
      "\n",
      "**ê° ë¶€ë¶„ì˜ ì˜ë¯¸:**\n",
      "\n",
      "*   **a, b, c:** 2ì°¨ ë°©ì •ì‹ì˜ ê³„ìˆ˜\n",
      "*   **Â±:** ë”í•˜ê¸° ë˜ëŠ” ë¹¼ê¸° (ë‘ ê°œì˜ í•´ë¥¼ ì˜ë¯¸)\n",
      "*   **âˆš:** ì œê³±ê·¼\n",
      "*   **bÂ² - 4ac:** íŒë³„ì‹ (Discriminant)ì´ë¼ê³  í•˜ë©°, í•´ì˜ ì¢…ë¥˜ë¥¼ íŒë³„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "**íŒë³„ì‹ì— ë”°ë¥¸ í•´ì˜ ì¢…ë¥˜:**\n",
      "\n",
      "*   **bÂ² - 4ac > 0:** ì„œë¡œ ë‹¤ë¥¸ ë‘ ì‹¤ê·¼ì„ ê°–ìŠµë‹ˆë‹¤.\n",
      "*   **bÂ² - 4ac = 0:** ì¤‘ê·¼(ì‹¤ê·¼)ì„ ê°–ìŠµë‹ˆë‹¤.\n",
      "*   **bÂ² - 4ac < 0:** ì„œë¡œ ë‹¤ë¥¸ ë‘ í—ˆê·¼ì„ ê°–ìŠµë‹ˆë‹¤. (ì‹¤ìˆ˜ ë²”ìœ„ì—ì„œëŠ” í•´ê°€ ì—†ìŠµë‹ˆë‹¤.)\n",
      "\n",
      "**ì˜ˆì‹œ:**\n",
      "\n",
      "ë‹¤ìŒ 2ì°¨ ë°©ì •ì‹ì˜ í•´ë¥¼ ê·¼ì˜ ê³µì‹ì„ ì‚¬ìš©í•˜ì—¬ êµ¬í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**2xÂ² + 5x - 3 = 0**\n",
      "\n",
      "1.  **ê³„ìˆ˜ í™•ì¸:**\n",
      "    *   a = 2\n",
      "    *   b = 5\n",
      "    *   c = -3\n",
      "\n",
      "2.  **ê·¼ì˜ ê³µì‹ ì ìš©:**\n",
      "    *   x = (-5 Â± âˆš(5Â² - 4 * 2 * -3)) / (2 * 2)\n",
      "    *   x = (-5 Â± âˆš(25 + 24)) / 4\n",
      "    *   x = (-5 Â± âˆš49) / 4\n",
      "    *   x = (-5 Â± 7) / 4\n",
      "\n",
      "3.  **ë‘ ê°œì˜ í•´ ê³„ì‚°:**\n",
      "    *   xâ‚ = (-5 + 7) / 4 = 2 / 4 = 1/2\n",
      "    *   xâ‚‚ = (-5 - 7) / 4 = -12 / 4 = -3\n",
      "\n",
      "ë”°ë¼ì„œ, 2ì°¨ ë°©ì •ì‹ 2xÂ² + 5x - 3 = 0ì˜ í•´ëŠ” x = 1/2 ì™€ x = -3 ì…ë‹ˆë‹¤.\n",
      "\n",
      "**ë‹¤ë¥¸ ì˜ˆì‹œ:**\n",
      "\n",
      "1.  **xÂ² - 4x + 4 = 0**\n",
      "    *   a = 1, b = -4, c = 4\n",
      "    *   x = (4 Â± âˆš(16 - 16)) / 2 = 2 (ì¤‘ê·¼)\n",
      "\n",
      "2.  **xÂ² + 2x + 5 = 0**\n",
      "    *   a = 1, b = 2, c = 5\n",
      "    *   x = (-2 Â± âˆš(4 - 20)) / 2 = (-2 Â± âˆš(-16)) / 2 (í—ˆê·¼)\n",
      "\n",
      "ì´ ì™¸ì—ë„ ë‹¤ì–‘í•œ 2ì°¨ ë°©ì •ì‹ì— ê·¼ì˜ ê³µì‹ì„ ì ìš©í•˜ì—¬ í•´ë¥¼ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "input_question = {\"question\": \"ê·¼ì˜ ê³µì‹ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ê³  ì˜ˆì‹œë¥¼ ë“¤ì–´ì¤„ë˜?\"}\n",
    "result = graph.invoke(input_question)\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bce8410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ë„ì™€ ì¸ë„ë„¤ì‹œì•„ëŠ” ì§€ë¦¬ì  ìœ„ì¹˜, ë¬¸í™”, ì—­ì‚¬ ë“± ì—¬ëŸ¬ ë©´ì—ì„œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤. ë‘ ë‚˜ë¼ì˜ ì£¼ìš” ì°¨ì´ì ì„ ìì„¸íˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**1. ì§€ë¦¬ ë° ìœ„ì¹˜:**\n",
      "\n",
      "*   **ì¸ë„:** ë‚¨ì•„ì‹œì•„ì— ìœ„ì¹˜í•˜ë©°, íŒŒí‚¤ìŠ¤íƒ„, ì¤‘êµ­, ë„¤íŒ”, ë¶€íƒ„, ë°©ê¸€ë¼ë°ì‹œ, ë¯¸ì–€ë§ˆì™€ êµ­ê²½ì„ ì ‘í•˜ê³  ìˆìŠµë‹ˆë‹¤. íŒë‘ìŠ¤íƒ„ ë°˜ë„ì— ìœ„ì¹˜í•˜ë©°, ë‹¤ì–‘í•œ ì§€í˜•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "*   **ì¸ë„ë„¤ì‹œì•„:** ë™ë‚¨ì•„ì‹œì•„ì™€ íƒœí‰ì–‘ ì‚¬ì´ì— ìœ„ì¹˜í•œ ì„¬ë‚˜ë¼ë¡œ, ìˆ˜ë§ì€ ì„¬ë“¤ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. ì„¸ê³„ì—ì„œ ê°€ì¥ í° êµ°ë„ êµ­ê°€ì…ë‹ˆë‹¤.\n",
      "\n",
      "**2. ì¸êµ¬ ë° ë¯¼ì¡±:**\n",
      "\n",
      "*   **ì¸ë„:** ì„¸ê³„ì—ì„œ ê°€ì¥ ì¸êµ¬ê°€ ë§ì€ ë‚˜ë¼ ì¤‘ í•˜ë‚˜ì´ë©°, ë‹¤ì–‘í•œ ë¯¼ì¡±ê³¼ ì–¸ì–´ê°€ ê³µì¡´í•©ë‹ˆë‹¤. íŒë‘êµ ì‹ ìê°€ ë‹¤ìˆ˜ë¥¼ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
      "*   **ì¸ë„ë„¤ì‹œì•„:** ì„¸ê³„ì—ì„œ ë„¤ ë²ˆì§¸ë¡œ ì¸êµ¬ê°€ ë§ì€ ë‚˜ë¼ì´ë©°, ë‹¤ì–‘í•œ ë¯¼ì¡±ê³¼ ì–¸ì–´ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìŠ¬ëŒêµ ì‹ ìê°€ ë‹¤ìˆ˜ë¥¼ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
      "\n",
      "**3. ë¬¸í™”:**\n",
      "\n",
      "*   **ì¸ë„:** íŒë‘êµ ë¬¸í™”ì˜ ì˜í–¥ì„ ë§ì´ ë°›ì•˜ìœ¼ë©°, ìš”ê°€, ì•„ìœ ë¥´ë² ë‹¤, ì¸ë„ ìŒì•…, ì¸ë„ ì˜í™” ë“± ë…íŠ¹í•œ ë¬¸í™”ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "*   **ì¸ë„ë„¤ì‹œì•„:** ë‹¤ì–‘í•œ ë¬¸í™”ì  ì˜í–¥ì„ ë°›ì•˜ìœ¼ë©°, ì¸ë„, ì¤‘êµ­, ì•„ë, ìœ ëŸ½ ë“±ì˜ ë¬¸í™”ê°€ í˜¼í•©ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì „í†µ ì¶¤, ìŒì•…, ë¯¸ìˆ , ê³µì˜ˆ ë“±ì´ ë°œë‹¬í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**4. ì—­ì‚¬:**\n",
      "\n",
      "*   **ì¸ë„:** ê³ ëŒ€ ë¬¸ëª…ì´ ë°œë‹¬í–ˆìœ¼ë©°, ë¶ˆêµ, ìì´ë‚˜êµ ë“± ë‹¤ì–‘í•œ ì¢…êµì˜ ë°œìƒì§€ì…ë‹ˆë‹¤. ì˜êµ­ ì‹ë¯¼ì§€ì˜€ë‹¤ê°€ ë…ë¦½í–ˆìŠµë‹ˆë‹¤.\n",
      "*   **ì¸ë„ë„¤ì‹œì•„:** ë‹¤ì–‘í•œ ì™•êµ­ë“¤ì´ ë²ˆì„±í–ˆìœ¼ë©°, ë„¤ëœë€ë“œ ì‹ë¯¼ì§€ì˜€ë‹¤ê°€ ë…ë¦½í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**5. ê²½ì œ:**\n",
      "\n",
      "*   **ì¸ë„:** ì„œë¹„ìŠ¤ì—…ì´ ë°œë‹¬í–ˆìœ¼ë©°, IT ì‚°ì—…ì´ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "*   **ì¸ë„ë„¤ì‹œì•„:** ì²œì—°ìì›ì´ í’ë¶€í•˜ë©°, ë†ì—…, ê´‘ì—…, ì œì¡°ì—…ì´ ë°œë‹¬í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**6. ì–¸ì–´:**\n",
      "\n",
      "*   **ì¸ë„:** íŒë””ì–´, ì˜ì–´, ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ ì§€ì—­ ì–¸ì–´ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "*   **ì¸ë„ë„¤ì‹œì•„:** ì¸ë„ë„¤ì‹œì•„ì–´ë¥¼ ì‚¬ìš©í•˜ë©°, ì§€ì—­ì ìœ¼ë¡œ ë‹¤ì–‘í•œ ì–¸ì–´ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "**ìš”ì•½:**\n",
      "\n",
      "| íŠ¹ì§• | ì¸ë„ | ì¸ë„ë„¤ì‹œì•„ |\n",
      "|---|---|---|\n",
      "| ìœ„ì¹˜ | ë‚¨ì•„ì‹œì•„ | ë™ë‚¨ì•„ì‹œì•„ ë° íƒœí‰ì–‘ |\n",
      "| ì£¼ìš” ì¢…êµ | íŒë‘êµ | ì´ìŠ¬ëŒêµ |\n",
      "| ì£¼ìš” ì–¸ì–´ | íŒë””ì–´, ì˜ì–´ | ì¸ë„ë„¤ì‹œì•„ì–´ |\n",
      "| ë¬¸í™”ì  ì˜í–¥ | íŒë‘êµ, ë¶ˆêµ | ì¸ë„, ì¤‘êµ­, ì•„ë, ìœ ëŸ½ |\n",
      "| ê²½ì œ | ì„œë¹„ìŠ¤ì—…, IT ì‚°ì—… | ì²œì—°ìì›, ë†ì—…, ì œì¡°ì—… |\n",
      "\n",
      "ì´ ì™¸ì—ë„ ë‘ ë‚˜ë¼ëŠ” ì •ì¹˜, ì‚¬íšŒ, ì™¸êµ ë“± ë‹¤ì–‘í•œ ì¸¡ë©´ì—ì„œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "input_question = {\"question\": \"ì¸ë„ì™€ ì¸ë„ë„¤ì‹œì•„ëŠ” ë­ê°€ ë‹¬ë¼?\"}\n",
    "result = graph.invoke(input_question)\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f3f2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
